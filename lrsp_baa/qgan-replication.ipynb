{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to install the required packages for running the qGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install qiskit==0.34.0 qiskit_machine_learning==0.3.0 qiskit_finance==0.3.0 qiskit-aer-gpu==0.10.2 --quiet\n",
    "!pip3 install torch==1.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path.append('.')\n",
    "import os\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time\n",
    "import pandas as pd\n",
    "import qiskit\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import experiment_utils\n",
    "from utils.custom_discriminator import CustomPyTorchDiscriminator\n",
    "from qiskit.circuit.library import TwoLocal\n",
    "from qiskit.opflow.gradients import Gradient\n",
    "from qiskit_finance.circuit.library import UniformDistribution\n",
    "from qiskit_machine_learning.algorithms import QGAN\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_dir = 'data/qgan-replication/'\n",
    "experiment_utils.check_create_dir(snapshot_dir)\n",
    "\n",
    "# Setting up Gan logger\n",
    "gan_logger = logging.getLogger('qiskit_machine_learning.algorithms.distribution_learners.qgan')\n",
    "formatter = logging.Formatter('%(asctime)s - gan-logger - %(message)s')\n",
    "s_handler = logging.StreamHandler()\n",
    "file_handler = logging.FileHandler(os.path.join(snapshot_dir, 'experiment.log'), mode='+w')\n",
    "gan_logger.addHandler(file_handler)\n",
    "s_handler.setFormatter(formatter)\n",
    "gan_logger.setLevel(logging.DEBUG)\n",
    "gan_logger.addHandler(s_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment settings\n",
    "n_samples = 20000\n",
    "\n",
    "simulator_device, torch_device = 'GPU', 'cuda:0'\n",
    "\n",
    "# Gan configurations\n",
    "batch_size = 2000\n",
    "n_epochs = 1000\n",
    "n_runs = 1\n",
    "seed = 7\n",
    "n_qubits = 7\n",
    "value_bounds = [0., 20.]\n",
    "rng = np.random.default_rng(seed)\n",
    "\n",
    "# Backends\n",
    "quantum_instance = experiment_utils.build_quantum_instance(\n",
    "                    'statevector_simulator',\n",
    "                    seed=seed,\n",
    "                    n_shots=8192,\n",
    "                    device=simulator_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "  dataset, \n",
    "  x_pmf,\n",
    "  value_bounds,\n",
    "  n_qubits,\n",
    "  batch_size,\n",
    "  n_epochs,\n",
    "  quantum_instance, \n",
    "  exp_dir,\n",
    "  seed, \n",
    "  torch_device):\n",
    "\n",
    "  # Setting up discriminator\n",
    "  discriminator = CustomPyTorchDiscriminator(device=torch_device)\n",
    "\n",
    "  # Setting up generator\n",
    "  init_circ = UniformDistribution(n_qubits)\n",
    "  gen_circ = TwoLocal(n_qubits, ['ry', 'rz'], 'cx', reps=1)\n",
    "  gen_circ.compose(init_circ, front=True, inplace=True)\n",
    "\n",
    "  # Setting up qGAN\n",
    "  qgan = QGAN(\n",
    "            dataset,\n",
    "            value_bounds, \n",
    "            num_qubits=[n_qubits], \n",
    "            batch_size=batch_size, \n",
    "            num_epochs=n_epochs,\n",
    "            discriminator=discriminator,\n",
    "            quantum_instance=quantum_instance,\n",
    "            snapshot_dir=exp_dir,\n",
    "            seed=seed\n",
    "          )\n",
    "\n",
    "  qgan.set_generator(gen_circ)\n",
    "\n",
    "  toc = time.time()\n",
    "  results = qgan.run()\n",
    "  tic = time.time()\n",
    "\n",
    "  print('Duration (min): ', (tic-toc) / 60 )\n",
    "\n",
    "  qgan.generator._gradient_function = None\n",
    "  if exp_dir:\n",
    "    experiment_utils.serialize_model(os.path.join(exp_dir,'qgan.pkl'), qgan)\n",
    "\n",
    "  # Generating probabilities\n",
    "  _, gen_probs = qgan.generator.get_output(quantum_instance)\n",
    "\n",
    "  # Computing fidelity\n",
    "  generated_state = experiment_utils.extract_statevector_from_generator(quantum_instance, qgan.generator)\n",
    "\n",
    "  input_state = np.sqrt(x_pmf)\n",
    "  input_state = input_state / np.linalg.norm(input_state)\n",
    "  computed_fidelity = experiment_utils.fidelity(input_state, generated_state)\n",
    "\n",
    "  # Plotting results\n",
    "  experiment_utils.plot_probs(\n",
    "    x_pmf, \n",
    "    gen_probs, \n",
    "    computed_fidelity, \n",
    "    x=np.linspace(0., value_bounds[1], 2**n_qubits),\n",
    "    experiment_dir=exp_dir)\n",
    "  \n",
    "  # Saving frequencies\n",
    "  dict_freqs = { \n",
    "                'discretization-pmf': x_pmf,\n",
    "                'real-data-freqs':  qgan._prob_data,\n",
    "                'generated-freqs': gen_probs \n",
    "               }\n",
    "               \n",
    "  file_name = os.path.join(exp_dir, 'frequencies.csv')\n",
    "  pd.DataFrame(dict_freqs).to_csv(file_name, index=False)\n",
    "\n",
    "  # Plotting GAN's performance\n",
    "  rel_entr = qgan.rel_entr\n",
    "  experiment_utils.plot_relative_entropy(rel_entr, experiment_dir=exp_dir)\n",
    "\n",
    "  g_loss = np.array(qgan.g_loss).reshape(-1)\n",
    "  d_loss = np.array(qgan.d_loss).reshape(-1)\n",
    "  experiment_utils.plot_gan_losses(g_loss, d_loss, experiment_dir=exp_dir)\n",
    "\n",
    "  # Saving performances\n",
    "  dict_metrics_per_epoch = {\n",
    "    'g-loss': g_loss, \n",
    "    'd-loss': d_loss, \n",
    "    'rel-entr': rel_entr\n",
    "  }\n",
    "\n",
    "  file_name = os.path.join(exp_dir, 'losses_rel_entr.csv')\n",
    "  pd.DataFrame(dict_metrics_per_epoch).to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lognormal distribution\n",
    "Varying the scale parameter of the distribution in $\\{0.5, 1, 2\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales_list = [0.5, 1, 2]\n",
    "\n",
    "gan_logger.info('Experiment for the LOGNORMAL distribution')\n",
    "\n",
    "for scale in scales_list:\n",
    "\n",
    "  gan_logger.info(f'Scale {scale}')\n",
    "\n",
    "  exp_dir = os.path.join(snapshot_dir, f'lognormal_s{str(scale)}')\n",
    "  experiment_utils.check_create_dir(exp_dir)\n",
    "\n",
    "  # Sampling dataset\n",
    "  loc = 0\n",
    "  dataset = experiment_utils.sample_from_distribution(\n",
    "              'lognormal', \n",
    "              n_samples,\n",
    "              loc, \n",
    "              scale,\n",
    "              random_state=rng\n",
    "            )\n",
    "\n",
    "  dataset %= value_bounds[1]\n",
    "\n",
    "  # Estimating PMF\n",
    "  x = np.linspace(0., value_bounds[1], 2**n_qubits)\n",
    "  distance = (x.max() - x.min()) / (2**n_qubits - 1)\n",
    "  delta = distance * .5\n",
    "  xcdf_plus = stats.lognorm.cdf(x + delta, s=1, scale=scale)\n",
    "  xcdf_minus = stats.lognorm.cdf(x - delta, s=1, scale=scale)\n",
    "  x_pmf = xcdf_plus - xcdf_minus\n",
    "\n",
    "  run_experiment(\n",
    "    dataset,\n",
    "    x_pmf,\n",
    "    value_bounds,\n",
    "    n_qubits,\n",
    "    batch_size,\n",
    "    n_epochs,\n",
    "    quantum_instance,\n",
    "    exp_dir,\n",
    "    seed,\n",
    "    torch_device\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laplace, Normal and Semicircular distributions\n",
    "\n",
    "Running one experiment for each distribution with specific parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_logger.info('Experiment for the LOGNORMAL distribution')\n",
    "\n",
    "distributions_params = { \n",
    "  'laplace': { 'loc':} \n",
    "}\n",
    "\n",
    "for scale in scales_list:\n",
    "\n",
    "  gan_logger.info(f'Scale {scale}')\n",
    "\n",
    "  exp_dir = os.path.join(snapshot_dir, f'lognormal_s{str(scale)}')\n",
    "  experiment_utils.check_create_dir(exp_dir)\n",
    "\n",
    "  # Sampling dataset\n",
    "  loc = 0 \n",
    "  #scale = 0.5\n",
    "  dataset = experiment_utils.sample_from_distribution(\n",
    "              'lognormal', \n",
    "              n_samples,\n",
    "              loc, \n",
    "              scale,\n",
    "              random_state=rng\n",
    "            )\n",
    "\n",
    "  dataset %= value_bounds[1]\n",
    "\n",
    "  # Estimating PMF\n",
    "  x = np.linspace(0., value_bounds[1], 2**n_qubits)\n",
    "  distance = (x.max() - x.min()) / (2**n_qubits - 1)\n",
    "  delta = distance * .5\n",
    "  xcdf_plus = stats.lognorm.cdf(x + delta, s=1, scale=scale)\n",
    "  xcdf_minus = stats.lognorm.cdf(x - delta, s=1, scale=scale)\n",
    "  x_pmf = xcdf_plus - xcdf_minus\n",
    "\n",
    "  run_experiment(\n",
    "    dataset,\n",
    "    x_pmf,\n",
    "    value_bounds,\n",
    "    n_qubits,\n",
    "    batch_size,\n",
    "    n_epochs,\n",
    "    quantum_instance,\n",
    "    exp_dir,\n",
    "    seed,\n",
    "    torch_device\n",
    "  )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7efeb9ef15fd4ece8b8010cbbac48a71e023cb9908a658c58961f9c34f96825c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
