{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1ad2693",
   "metadata": {},
   "source": [
    "# Experiments on VQC\n",
    "### Extra info and data (Figure 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12ae81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit.providers.aer.backends import AerSimulator\n",
    "\n",
    "from qclib.machine_learning.datasets import digits\n",
    "from qclib.state_preparation import BaaLowRankInitialize\n",
    "from qclib.state_preparation.util.baa import adaptive_approximation\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff80e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset load.\n",
    "\n",
    "matrix_dim = 8\n",
    "sample_total, training_input, test_input, class_labels = digits.load(classes=[0, 1],\n",
    "                                                                     training_size=40,\n",
    "                                                                     test_size=10,\n",
    "                                                                     random_seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae241ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "baa_strategy = 'brute_force'\n",
    "baa_low_rank = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51826414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset numerical analysis.\n",
    "# Average number of CNOTs, depth, and fidelity.\n",
    "\n",
    "def _fidelity(input_state, transpiled_circuit):\n",
    "    backend = AerSimulator()\n",
    "    transpiled_circuit.save_statevector()\n",
    "    ket = backend.run(transpiled_circuit).result().get_statevector()\n",
    "    bra = np.conj(input_state)\n",
    "\n",
    "    return np.abs(bra.dot(ket))**2\n",
    "\n",
    "def _counts(input_state, l, result, method='baa'):\n",
    "    if method == 'qiskit':\n",
    "        n_qubits = int(np.log2(len(input_state)))\n",
    "        circuit = QuantumCircuit(n_qubits)\n",
    "        circuit.initialize(input_state)\n",
    "    else:\n",
    "        circuit = BaaLowRankInitialize(input_state, opt_params={'max_fidelity_loss':l, 'strategy':baa_strategy, 'use_low_rank':baa_low_rank}).definition\n",
    "    transpiled_circuit = transpile(circuit, basis_gates=['u1','u2','u3', 'cx'], optimization_level=3)\n",
    "    \n",
    "    count_ops = transpiled_circuit.count_ops()\n",
    "    n_cx = 0\n",
    "    if 'cx' in count_ops:\n",
    "        n_cx = count_ops['cx']\n",
    "    n_dp = transpiled_circuit.depth()\n",
    "\n",
    "    fidelity = _fidelity(input_state, transpiled_circuit)\n",
    "\n",
    "    result.append([l, n_cx, n_dp, fidelity])\n",
    "        \n",
    "def _grid_search(input_state, fidelity_loss=None):\n",
    "    result = []\n",
    "    if fidelity_loss is None:\n",
    "        fidelity_loss = [i/10 for i in range(11)]\n",
    "\n",
    "    n = int(np.log2(len(input_state)))\n",
    "    for l in fidelity_loss:\n",
    "        _counts(input_state, l=l, result=result, method='baa')\n",
    "    \n",
    "    return result\n",
    "\n",
    "def _print_results(results):\n",
    "    fidelity_loss = [r[0] for r in results[0]]\n",
    "\n",
    "    n_cx = {}\n",
    "    n_dp = {}\n",
    "    fidelity = {}\n",
    "    for l in fidelity_loss:\n",
    "        n_cx[l] = []\n",
    "        n_dp[l] = []\n",
    "        fidelity[l] = []\n",
    "\n",
    "    for result in results:\n",
    "        for l in fidelity_loss:\n",
    "            n_cx[l].extend([r[1] for r in result if r[0]==l])\n",
    "            n_dp[l].extend([r[2] for r in result if r[0]==l])\n",
    "            fidelity[l].extend([r[3] for r in result if r[0]==l])\n",
    "    \n",
    "    print('AVG:')\n",
    "    for l in fidelity_loss:\n",
    "        avg_cx = sum(n_cx[l]) / len(n_cx[l])\n",
    "        avg_dp = sum(n_dp[l]) / len(n_dp[l])\n",
    "        avg_fidelity = sum(fidelity[l]) / len(fidelity[l])\n",
    "        print('l={3}\\tCNOTs={0}\\tdepth={1}\\tfidelity={2}'.format(avg_cx, avg_dp, avg_fidelity, l))\n",
    "    \n",
    "    print('STD:')\n",
    "    for l in fidelity_loss:\n",
    "        std_cx = np.std(n_cx[l])\n",
    "        std_dp = np.std(n_dp[l])\n",
    "        std_fidelity = np.std(fidelity[l])\n",
    "        print('l={3}\\tCNOTs={0}\\tdepth={1}\\tfidelity={2}'.format(std_cx, std_dp, std_fidelity, l))\n",
    "\n",
    "results = []\n",
    "print('training set')\n",
    "for i in training_input:\n",
    "    print(f'class {i}', end=' ')\n",
    "    for input_state in training_input[i]:\n",
    "        print('.', end='')\n",
    "        results.append(_grid_search(input_state))\n",
    "    print()\n",
    "print('test set')\n",
    "for i in test_input:\n",
    "    print(f'class {i}', end=' ')\n",
    "    for input_state in test_input[i]:\n",
    "        print('.', end='')\n",
    "        results.append(_grid_search(input_state))\n",
    "    print()\n",
    "\n",
    "_stdout = sys.stdout\n",
    "with open('save/digits_dataset_info.txt', 'w') as f:\n",
    "    sys.stdout = f\n",
    "    _print_results(results)\n",
    "    sys.stdout = _stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30950879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots examples of the states that represent the digits.\n",
    "\n",
    "def plot_digits(digits, labels, text):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    _, axes = plt.subplots(nrows=1, ncols=len(digits), figsize=(10, 3))\n",
    "    for ax, digit, label in zip(axes, digits, labels):\n",
    "        ax.set_axis_off()\n",
    "        image = digit[:int(matrix_dim**2)].reshape(matrix_dim, matrix_dim)\n",
    "        ax.imshow(image, cmap=plt.cm.gray_r, interpolation='none')\n",
    "        ax.set_title(label)\n",
    "\n",
    "    plt.savefig(f'save/digits_{text}.pdf')\n",
    "    plt.show()\n",
    "\n",
    "for sample in range(3):\n",
    "    print(f'sample: {sample}')\n",
    "    original = {}\n",
    "    for i in training_input:\n",
    "        original[i] = training_input[i][sample]\n",
    "        original[i] = training_input[i][sample]\n",
    "\n",
    "    for digit in training_input:\n",
    "        _digits = []\n",
    "        _labels = []\n",
    "        for l_max in [i/10 for i in range(11)]:\n",
    "            node = adaptive_approximation(original[digit], max_fidelity_loss=l_max, strategy=baa_strategy, use_low_rank=baa_low_rank)\n",
    "            _digits.append(node.state_vector()**2)\n",
    "            _labels.append(str(l_max))\n",
    "        \n",
    "        plot_digits(_digits, _labels, f'{digit}_{sample}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109bed7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
